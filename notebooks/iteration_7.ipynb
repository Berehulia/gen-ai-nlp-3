{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtcRLw8iYbHn",
    "outputId": "26ef2568-1bea-4315-ba49-42d49603e13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers bitsandbytes langchain langchain-community langchain-huggingface langchain-text-splitters pymupdf faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVX8NBrGYbHp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAElqhptYbHq"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"Qwen/Qwen3-30B-A3B-Instruct-2507-FP8\"\n",
    "TRAIN_FILE = \"zno.train.jsonl\"\n",
    "TEST_FILE = \"zno.test.jsonl\"\n",
    "OUTPUT_FILE = \"submission.csv\"\n",
    "DEBUG_LIMIT = None\n",
    "\n",
    "DATA_FOLDER = \"ubertext_data\"\n",
    "WIKIPEDIA_URL = \"https://lang.org.ua/static/downloads/ubertext2.0/wikipedia/cleansed/ubertext.wikipedia.filter_rus_gcld+short.text_only.txt.bz2\"\n",
    "INDEX_PATH = \"faiss_index\"\n",
    "CHUNKS_CACHE = \"chunks_cache.pkl\"\n",
    "EMBEDDING_MODEL = \"intfloat/multilingual-e5-small\"\n",
    "TOP_K = 1\n",
    "CHUNK_SIZE = 4000\n",
    "CHUNK_OVERLAP = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6CokUmwD93b",
    "outputId": "4807232d-e200-41a4-b314-9f8bf2cf39bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package lbzip2.\n",
      "(Reading database ... 121689 files and directories currently installed.)\n",
      "Preparing to unpack .../lbzip2_2.5-2.3_amd64.deb ...\n",
      "Unpacking lbzip2 (2.5-2.3) ...\n",
      "Setting up lbzip2 (2.5-2.3) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "--2026-01-13 20:26:49--  https://lang.org.ua/static/downloads/ubertext2.0/wikipedia/cleansed/ubertext.wikipedia.filter_rus_gcld+short.text_only.txt.bz2\n",
      "Resolving lang.org.ua (lang.org.ua)... 65.21.91.242\n",
      "Connecting to lang.org.ua (lang.org.ua)|65.21.91.242|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 845007569 (806M) [application/octet-stream]\n",
      "Saving to: ‘ubertext_data/ubertext.wikipedia.filter_rus_gcld+short.text_only.txt.bz2’\n",
      "\n",
      "ubertext.wikipedia. 100%[===================>] 805.86M  75.1MB/s    in 11s     \n",
      "\n",
      "2026-01-13 20:27:00 (72.1 MB/s) - ‘ubertext_data/ubertext.wikipedia.filter_rus_gcld+short.text_only.txt.bz2’ saved [845007569/845007569]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -qq lbzip2\n",
    "!mkdir -p {DATA_FOLDER}\n",
    "!wget -nc -P {DATA_FOLDER} {WIKIPEDIA_URL}\n",
    "!cd {DATA_FOLDER} && lbzip2 -dk *.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669,
     "referenced_widgets": [
      "527cf733f1d74da7b42662d66fbc057b",
      "53085da6e025464d8e489c3e2c6ca606",
      "9a75a0712a1442d08af46b075e12a34f",
      "156fcc46a1254b80834128cefd6053a8",
      "497dabc78b514c5eb159526e20f2ca94",
      "89691ff630ce4b1bbe77eb7ab8e9abb0",
      "64abba224d224f6bac569496685a8823",
      "030a5fb60e3f43069ce47bf7704620df",
      "b59d8cb55b6c41e295fe54dd81a4df24",
      "22f7d752885c467e94e317d31811e7ea",
      "12eb93e1c905432c8994c6e63184d49b",
      "2c7482edb81a4db6a5e69b5cc8eb8f2c",
      "9c9c9aa2e1264fac9783eae2eeae22e8",
      "8065c36916b34d93a2f7feb129ad8c50",
      "0d52b3c832e049c4bcd1c10c00532256",
      "1ebf8434b21e4ddfb45cd7f596737489",
      "377fdf685be84fcc880ebee567b34491",
      "a5b406afcece49c98e71b116661e2d1f",
      "4a75065ae88542eba5997fbb56186dee",
      "53176dc947bb42daac694b7ae1077a3a",
      "f96b1a1310fd41f7ae568a3de7ea16b9",
      "3d864260555a47029067901b5a715cb5",
      "22436a9f158f49b5959018db9691ff09",
      "cb5fb270ed0648e094925876bbf928a2",
      "a7098e600b1d4d4fa5d06b55ce4fe00e",
      "f165b4626cbe4665b7001769294be057",
      "eecd23f3c68e4fff91329566c32529cd",
      "6975ba0f86ec4371a5943e78993f7d28",
      "75117f48ce2c45348059596b6fb36c85",
      "95798fdaed6841e28ba1a7c84482fd0d",
      "6aae45bf00644e93a2adfe83e10b1be0",
      "9f685052b23042ad8ef5edf3734d8f1f",
      "41b48082ae834f8da6cb828ebf12e46c",
      "b9df6a4670e5425db931da75532166cd",
      "d8865809c3084273a009ef574251c973",
      "8399023323ab43039aa235b4eae23955",
      "1f7eef353b2443ffa3d674d0966b1840",
      "4356abc1e51a4d6da672164f5f33aa01",
      "68d1aecd719b4b3d8a4aae59f06df995",
      "c6e871a707cb48a29576da95d7220e26",
      "c3375889477d4818ac84c529e97c4c08",
      "28f12701fae6497bb3c1fc60d00f92a8",
      "3fec4185bd6641138e2d75cba3b454c0",
      "b9947d5891684c419a702c6d208fcd2d",
      "0df62edd682f458685934c210b8299b8",
      "bf83a7ebfcb4468d8550b4afddf19aff",
      "78eda79d588f49ad8172609e3191d880",
      "5dc3e6f3805d4fb68418bdede7e7a1d3",
      "623eed428be04cf58a51b7e46fb76f7b",
      "486ccf744986401ca1e1049791265000",
      "1bcdd14060384a1cae227666b418d3e6",
      "8474d6c329564d39b28b87888cbf3bf3",
      "1712a081b6d04c129e72529e0be8df2f",
      "ef64ed6f87d446a79a337b3f20481f9a",
      "e4f705617abf4129908d94777ad971b3",
      "6826656965a3458490caa3b5d811d825",
      "9426a663e1ec46c09637288c7cbdcc78",
      "f84ce8e8b73d41df92384f113afaec0a",
      "9fdba99dbfe84c5db96a4485108bfbbb",
      "172ef734fd6b466b94eada57b3c92547",
      "bd4bf817a7a7477f8f6889260ef3f36a",
      "c651244174784112bb3f65e8347159e5",
      "9305334e7e0b43439c89743d29e57cee",
      "7719f13122d94a0c96b27220872f7bc6",
      "5892b38014ad4c3eb6fb34b1b8cdcac9",
      "d42becfe9b3e45b3ba0270c5952e3477",
      "58a11ddac62d463792d1d3cecb191a49",
      "654b480e47e149a0925ac109b6e8e4f7",
      "31a9629a51a447c7b132860639795ce6",
      "772566dd996d48ccaa93e185467d52a7",
      "6b8691cdca364fb3988f35f1dd5de0d0",
      "69491edc557e4f109b9b3298a5fed474",
      "7fa4c53cb7cf4082b23978f86c486d84",
      "074b6ba9e8b34e44ae285f20ae9dec53",
      "5eb420daf42b42e09049af06b5a130d7",
      "3511d34a5a0f48878aa9cf75818b01cc",
      "5a713d6f3a304498b6be0673832f3544",
      "f1a7fadd2c5a4149be900128eab95551",
      "bb023b6b82574e0b80ea56b9f912e237",
      "f2a924721adf48bcbf6cd7201217c470",
      "9463920c7ffc46f08652843b7f37afd8",
      "d7b611d957e44dea91894f48a31a7210",
      "00c8e0a7ce6640d28397fda7255d1677",
      "3732cdaf72fb43309a99bee873a6cb21",
      "d9343172fa244596bed504ec396748bd",
      "171fbf6b02274c90afa0d66f445cb0dc",
      "9bd5967c0d5b4530a744d67f74219205",
      "103bee22d4e74bcab910c12788c2d611",
      "4a32a813fa40465fbf3a7d33f5b1cad0",
      "ebb58a305ed045db8a23cd34c12b1827",
      "ce57ebd6beea46c8ad5b31d2bd4b9052",
      "bd837215f85e4e98b600d8e1d05484c8",
      "98866e8e0f8043d5ae584973be04dedc",
      "7569039ef50c41c48ef73120aab658eb",
      "480085f5af684e29997ae39bd17f2118",
      "33444459b0c648789797b02771908506",
      "b03cf3bbbfb8404c860615e130eaed8e",
      "4d687be5110744f3990891cc231799f3",
      "27c03992ba2a46218df5344d40b2c6a9",
      "f75305768fca4599b4e59ae548b64ced",
      "f375386521ad45199f2e51c661feea80",
      "10bfc9be5fe64c0095b15fe85a26b99c",
      "413271098f14456cb210ca5555a17d2e",
      "7e268195d11149e9aff879f9e5567fb5",
      "1930659e804e41fe87562b576bec98c9",
      "5a12b1f3cd0148be87671b91ec8dc045",
      "7c6ac7d1d7f544d48f8d53b49acc0b91",
      "9f41be57ffe24d3b9cdf0cfbe29685dd",
      "a6a08b8fd0b1486d8aab15e415baae58",
      "a70d4dbe4e3c46389e15b593467326b3",
      "61189d9a3e204a7b80408f987a0e2dea",
      "17d8d1867bfc4f3e877827fc00709773",
      "81b34d67063f4d23a3b0e2c8c359963b",
      "fb12353d619c4398827dbd40a92c2d8b",
      "ab3e742784b048d2b1b0112adb119016",
      "d8478b355d78400191d83f9ffc5e3411",
      "7610818d8a1a4866a7bec1639338b414",
      "5434825db05f482e8b0a072d556daa41",
      "857d58ffd61c4955b619c6a11f5fe452",
      "e8fc47d12db34fb7b86873e56817a75e",
      "4df735113da94fcb87aaacbe42dc91a0",
      "4196eb102e0a4c83a88a71d60c285236",
      "e8196220bd1f498e8dd32a4f21bbcbc8",
      "71d7de54539c4cfd8c658582e89e82fc",
      "8bb8b9edaadf48f3aefd984bdeaa22d9",
      "734d061b23cf476584f3e5b1cffe8b1b",
      "091d1a3ef405442fb2e6ac79b2af9f02",
      "290467010e774bde9b1ee219916f78fe",
      "4bb5c8f172e24cda981b30493c540279",
      "666d46719eeb407d8d9b7808a637b324",
      "39e57feb1f0543db85f9d0982433e5a0",
      "220d98ddeb844c17aae98148601e0566",
      "874ca045b80c43c48dd937a4381f9711",
      "9e914b7c893e4bb2aceb4b14138e655a",
      "b8a3895c3b2c4955b2ba0f1ab58b5c88",
      "cb6d2e3a2f264065b78dc878ea8da726",
      "c3de9184d4db4d9782df3d976dbbc1fe",
      "3635c1bb2d034e9081ccd3fc885618f7",
      "6c48b8d60977420f9c176b3205279606",
      "e0f7d99792f7454f875c7dc6af08fc86",
      "75506dd5cc3543a1a3ba6b50821b1719",
      "5601ddb0164f45b1abbf46fc81d94741",
      "188b531cc2c64f2eaa2b62ce9fef9291"
     ]
    },
    "id": "0qVO9ZItYbHq",
    "outputId": "a6510995-32a2-4797-f3ea-4f67a941bf7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527cf733f1d74da7b42662d66fbc057b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7482edb81a4db6a5e69b5cc8eb8f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22436a9f158f49b5959018db9691ff09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df6a4670e5425db931da75532166cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df62edd682f458685934c210b8299b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6826656965a3458490caa3b5d811d825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a11ddac62d463792d1d3cecb191a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7fadd2c5a4149be900128eab95551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a32a813fa40465fbf3a7d33f5b1cad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75305768fca4599b4e59ae548b64ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61189d9a3e204a7b80408f987a0e2dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4196eb102e0a4c83a88a71d60c285236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874ca045b80c43c48dd937a4381f9711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTYf_JuCYbHr"
   },
   "outputs": [],
   "source": [
    "def load_data(filepath, limit=None):\n",
    "    data = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    if limit:\n",
    "        data = data[:limit]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJWtkfr7D93b"
   },
   "outputs": [],
   "source": [
    "ALLOWED_CHARS = set(\n",
    "    \"абвгґдеєжзиіїйклмнопрстуфхцчшщьюя\"\n",
    "    \"АБВГҐДЕЄЖЗИІЇЙКЛМНОПРСТУФХЦЧШЩЬЮЯ\"\n",
    "    \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    \"0123456789\"\n",
    "    \" \\t\\n\"\n",
    "    \".,;:!?-—–()[]{}\\\"'«»…\"\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned = ''.join(c if c in ALLOWED_CHARS else ' ' for c in text)\n",
    "    cleaned = re.sub(r' +', ' ', cleaned)\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5aOovVRFe5D"
   },
   "outputs": [],
   "source": [
    "def is_valid_chunk(text, min_length=100):\n",
    "    cleaned = clean_text(text)\n",
    "    if len(cleaned) < min_length:\n",
    "        return False\n",
    "\n",
    "    alpha_chars = [c for c in cleaned if c.isalpha()]\n",
    "    if len(alpha_chars) < 20:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOHKrxjWD93c"
   },
   "outputs": [],
   "source": [
    "def build_index(data_folder=DATA_FOLDER, output_path=INDEX_PATH, max_chars=None, use_cache=True):\n",
    "    import time\n",
    "\n",
    "    if use_cache and os.path.exists(CHUNKS_CACHE) and max_chars is None:\n",
    "        print(f\"Loading cached chunks from {CHUNKS_CACHE}...\")\n",
    "        start = time.time()\n",
    "        with open(CHUNKS_CACHE, \"rb\") as f:\n",
    "            documents = pickle.load(f)\n",
    "        print(f\"  Loaded {len(documents):,} chunks in {time.time()-start:.1f}s\")\n",
    "    else:\n",
    "        txt_files = glob.glob(f\"{data_folder}/*.txt\")\n",
    "        if not txt_files:\n",
    "            raise ValueError(f\"No text files found in {data_folder}\")\n",
    "\n",
    "        print(f\"Found {len(txt_files)} text file(s)\")\n",
    "        for f in txt_files:\n",
    "            size_mb = os.path.getsize(f) / (1024 * 1024)\n",
    "            print(f\"  - {f}: {size_mb:.1f} MB\")\n",
    "\n",
    "        if max_chars:\n",
    "            print(f\"\\n⚠️  TEST MODE: limiting to {max_chars:,} chars per file\")\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE,\n",
    "            chunk_overlap=CHUNK_OVERLAP,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "        )\n",
    "\n",
    "        print(\"\\n[Step 1/3] Reading and chunking files...\")\n",
    "        all_chunks = []\n",
    "        for path in txt_files:\n",
    "            start = time.time()\n",
    "            print(f\"  Reading {os.path.basename(path)}...\", end=\" \", flush=True)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read(max_chars) if max_chars else f.read()\n",
    "            print(f\"{len(text):,} chars\", end=\" -> \", flush=True)\n",
    "\n",
    "            chunks = text_splitter.create_documents([text], metadatas=[{\"source\": path}])\n",
    "            print(f\"{len(chunks):,} chunks ({time.time()-start:.1f}s)\")\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "        print(f\"  Total raw chunks: {len(all_chunks):,}\")\n",
    "\n",
    "        print(\"\\n[Step 2/3] Filtering chunks...\")\n",
    "        documents = []\n",
    "        for c in tqdm(all_chunks, desc=\"Filtering\"):\n",
    "            if is_valid_chunk(c.page_content):\n",
    "                c.page_content = clean_text(c.page_content)\n",
    "                documents.append(c)\n",
    "\n",
    "        print(f\"  Valid chunks after filtering: {len(documents):,} ({len(documents)/len(all_chunks)*100:.1f}%)\")\n",
    "\n",
    "        if use_cache and max_chars is None:\n",
    "            print(f\"\\n  Saving chunks to {CHUNKS_CACHE}...\")\n",
    "            with open(CHUNKS_CACHE, \"wb\") as f:\n",
    "                pickle.dump(documents, f)\n",
    "            print(f\"  Cache saved!\")\n",
    "\n",
    "    print(\"\\n[Step 3/3] Building embeddings and FAISS index...\")\n",
    "    print(f\"  This will process {len(documents):,} chunks...\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        model_kwargs={\"device\": \"cuda\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": True, \"batch_size\": 256},\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    print(f\"  Embeddings + index built in {time.time()-start:.1f}s\")\n",
    "\n",
    "    vectorstore.save_local(output_path)\n",
    "    print(f\"\\nIndex saved to {output_path}: {len(documents):,} chunks\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ1ltNfK1BZ-"
   },
   "outputs": [],
   "source": [
    "def load_index(index_path=INDEX_PATH):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        model_kwargs={\"device\": \"cuda\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    return FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBm4gV3l1Crl"
   },
   "outputs": [],
   "source": [
    "def get_context(vectorstore, question, k=TOP_K):\n",
    "    docs = vectorstore.similarity_search(f\"query: {question}\", k=k)\n",
    "    return \"\\n\".join([f\"[{i+1}] {d.page_content}\" for i, d in enumerate(docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYsITIbXYbHr"
   },
   "outputs": [],
   "source": [
    "def format_prompt(item, tokenizer, context=\"\"):\n",
    "    question = item[\"question\"]\n",
    "    options_text = \"\"\n",
    "    valid_markers = []\n",
    "\n",
    "    for ans in item[\"answers\"]:\n",
    "        options_text += f\"{ans['marker']}) {ans['text']}\\n\"\n",
    "        valid_markers.append(ans[\"marker\"])\n",
    "\n",
    "    system_prompt = \"Ви спеціаліст в українській літературі, мові та історії. Ви знаєте як складаються професійні тести на кшталт ЗНО. Перед вами питання екзамену. Визначьте правильну відповідь. Виведіть ТІЛЬКИ одну букву (А, Б, В, Г або Д) без пояснень і без крапок.\\n\"\n",
    "\n",
    "    if context:\n",
    "        system_prompt = system_prompt + f\"RAG Контекст:\\n{context}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Питання:{question}\\nВаріанти:\\n{options_text}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    return text, valid_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vR5BzRksYbHs"
   },
   "outputs": [],
   "source": [
    "def parse_answer(content, valid_markers):\n",
    "    match = re.search(r\"([АБВГД])\", content)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"А\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKDZMELpYbHs"
   },
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, item, vectorstore=None):\n",
    "    context = get_context(vectorstore, item[\"question\"]) if vectorstore else \"\"\n",
    "    prompt, valid_markers = format_prompt(item, tokenizer, context)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # print(prompt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True).strip()\n",
    "    return parse_answer(response, valid_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjRI819LYbHs"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, vectorstore=None, filepath=TRAIN_FILE, limit=DEBUG_LIMIT):\n",
    "    data = load_data(filepath, limit)\n",
    "    correct = 0\n",
    "    total = len(data)\n",
    "    predictions = []\n",
    "\n",
    "    for idx, item in enumerate(tqdm(data, desc=\"Evaluating\")):\n",
    "        predicted = predict(model, tokenizer, item, vectorstore)\n",
    "        expected = item[\"correct_answers\"][0]\n",
    "        is_correct = predicted == expected\n",
    "        predictions.append({\"id\": idx, \"predicted\": predicted, \"expected\": expected, \"correct\": is_correct})\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        tqdm.write(f\"[{idx}] predicted: {predicted}, expected: {expected}, correct: {is_correct}\")\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    return {\"correct\": correct, \"total\": total, \"accuracy\": accuracy, \"predictions\": pd.DataFrame(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veaXUulhYbHt"
   },
   "outputs": [],
   "source": [
    "def create_submission(model, tokenizer, vectorstore=None, filepath=TEST_FILE, output=OUTPUT_FILE, limit=DEBUG_LIMIT):\n",
    "    data = load_data(filepath, limit)\n",
    "    results = []\n",
    "\n",
    "    for idx, item in enumerate(tqdm(data, desc=\"Creating submission\")):\n",
    "        predicted = predict(model, tokenizer, item, vectorstore)\n",
    "        results.append({\"id\": item.get(\"id\", idx), \"correct_answers\": predicted})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output, index=False)\n",
    "    print(f\"Submission saved to {output}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryLlajp7YbHt"
   },
   "outputs": [],
   "source": [
    "def run_pipeline(model, tokenizer, vectorstore=None):\n",
    "    eval_results = evaluate(model, tokenizer, vectorstore)\n",
    "    # df ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719,
     "referenced_widgets": [
      "4df89ec99f4b4944abae4f8756d96303",
      "d4efdbf075964a78b7b5b12ffcf58e8e",
      "043a2401b60f4965a9d21485c6d8eaea",
      "e667d803e2e744cc808e5ea7ddb74f1e",
      "c091ae7d9b3d4f228e6ee64b57652ab4",
      "0b59fd5146e147d7a9307be712e22adb",
      "54ad27ad53454f95a67cb04ae5d9c61a",
      "568315293f1f4bd0b9ccb54382cb0b21",
      "e6223bb90da24dd9a5b56001388681dc",
      "bfacd5ccec264502bfa42cbe9ed502a3",
      "24439d55ada7472aa4cdfc4b34395c65",
      "0984744dc2884abfa7e7c020332cb8fb",
      "8ebb59d00e604cf585832dc7864188d8",
      "234a1ff6be72472a98837ebbf077bf30",
      "13042859df32416b985340753b9a71f2",
      "ca230dc11a14476dad14a93d4690de7e",
      "1e07b1e6e7004ec793cd9f996eb53b87",
      "76ffa3eaaed641bea746ef4b62668e11",
      "d3f42044bc114493bb7fee9dba7e46c9",
      "2ccf9c2a4803449a9a4532e8494a1180",
      "486cc572f961480a84a177c3945fe0f9",
      "b17a6c0aa0a04eaabd3e25cfd71ece28",
      "28a3fbbffec74c2db48b78a8f0c3c146",
      "ddd8bc043ba745ebb5a9d4029a4c5b9b",
      "fc238d80da2f4f4b81a7104c535d00d4",
      "d66f489e9ffe47d8a9c5a8bb5e9d4921",
      "c61e8c691c9b4f48803d1dec6551da03",
      "c7df1f789a80477985b87284a98e6205",
      "0603377780a54f6690f95ce6f1d11536",
      "4246f93decc94f7a92b2915057d61950",
      "43aed4e487ab4162b09c492815f1d8fb",
      "b35ad68b18cc492c9912dfba26cfe4bf",
      "d0a8e2ff38b7466d96c0c2a8b978eb2e",
      "ff62af56e7854cf982b294d08f8ce6dc",
      "b086ff92d2d44117867ec3b21363da72",
      "bab969ab57b64f5897ad42c31f939dbc",
      "dbb84f54577744379785857eb38f92f9",
      "8873805eabe849ebb9d81689122e3a93",
      "cb5b131a7d09432ca592f4c8326550b5",
      "ccf1ac7058a94e8a800db5b64434c144",
      "1f886aebfd12444ea339c2046814fae2",
      "d1436d1e832c44108ee4c772deaa8091",
      "cb816e764d4d4728a90504a42e738146",
      "28e7851786834c5d8fcd639aa3ccf68d",
      "cd63744934274dc3991788ff1b07a51d",
      "073541ea391d4b158a41bc3faa9e32b4",
      "fe75a961c86f4ace8ab7ec5c7f453f66",
      "5479d7d1886e42ff9c3c497bb2678c20",
      "8b73827a581b4926bd8e5b32a6bf1876",
      "1a89ed8ee5f84284a5b7556c7c05ec03",
      "466713862dd8411c9c2fd450051a7f0b",
      "85ea77c358de4f0c838fba3a77719dfa",
      "c0529c459dd041d9a9cc4eaa9b7e51a8",
      "cc639360846f40f18ca514fb6744edd8",
      "9cb99f5ec2574691a2a99b6cea7e500d",
      "eece2a69bff149338a1d066fb5673e7a",
      "77d1e01233f042d0b2e5dccec6968a3d",
      "2bf2eefe98fe477690402e4959bae7dc",
      "2461661ac8f943f684a2525f25bf57b4",
      "2c6fa6f8babb45a4a9e5c29a265f7af4",
      "5051eca6db0d4dfdb7c89fcbbc3b01d2",
      "363c064e88034378a085a6c736cd0192",
      "51cb9014479e4c5cb99574a6782a28e9",
      "bf042aa4738f4f149d8f757b929256a0",
      "2dd2912246734c23b8575a9453910e04",
      "c84f015f559f4a298449f04a228613a8",
      "9c6be14054b74a93beffb7f93d02ccb8",
      "5b91804c704940e6876af45f3eabae3c",
      "a237b03c7e034d84ad16e00b6c266d15",
      "929a3a52bd464376aa197fc9cf89283c",
      "09910765b9bf4185a77cdeb394680825",
      "e2d2931d1c15467a98538eadbeab451b",
      "5968e14472eb46b9b4ce03a1a3d9603e",
      "614063bfbb434cd892cfb53d9c3a2193",
      "9ba167949f284b9bbd4de5eaef541f7d",
      "f6a9a27e1746432182089ca8b6fee216",
      "77a1f77bbdd74f64b54d69c0241c488b",
      "3e98c5a927a345c187d7c3563cb9bd8b",
      "546d9e01ea32411793d1857c5e2fba76",
      "52c467d414a145c29955d1d99c028f7e",
      "1274b7cd8d9e4787bb7ca7aed200a5b5",
      "56839a0f789540e5bb332f25f5663dc3",
      "2064133044f24621b73d56014b516943",
      "6655b714fa35405ab4cde5ae46485a1a",
      "c677c2211a4346e18a6c933dbf3f9df3",
      "a75816a4abf947dea24ef20eb64288ca",
      "37026cb348b140c9b173919b42efeaf3",
      "0f9f06fc7b2342e38e8f883d6187c024",
      "4154d93c864f41349bef69a1891fded8",
      "29f9df32103747d8bffc9c94fbf41c21",
      "700e4fea47dc411caacc6333323423d4",
      "1aec3d43187d49b4b54117b265877aef",
      "a1c6aac7df554933b74516891e350a32",
      "d356ab050a804b73bdcd15ffbf96ff4b",
      "0764b52b5ef843518f10b41327ee680d",
      "a94d04d2bc134eb580415d7af479deff",
      "052d671f13f84eff98372767181b47b6",
      "ab4a6c2c621c46c5ba17f984793b8626",
      "bba8c04f7b04453cb5ef7ababebbcff0",
      "69f4be0ab706419b876626f80bea5fc6",
      "ea59d3516b164973859c6fe9499a5905",
      "ca33c4eefc9d43778c46c750f17c0f29",
      "edc8670ddbf54b76a2ef40bf8f77a6a7",
      "c34a9f4f19b34c5993907f0c1ff4969f",
      "4c01970a884c441c8841d36edf8f8c1c",
      "2ac7e8318bb2455d91d98f5b76c82c9e",
      "2afc408287f4408c9ae193eaa56cef2d",
      "0e2f18eabac44fcd8fb5602ccfbc3d7f",
      "7738b6c4ac594685ba48e0b386d36cca",
      "8f4ea8efaf7349fd9e19c1e20e857b7d",
      "a1fd96b67de8466db62fb70f2b86367f",
      "3629b4f1723243158ff908e00a715f11",
      "f5fa8fe4d84c433abdb056251c933121",
      "24b707e7de014d049e29b25ee088c2c6",
      "096c8f312ce344e3affab6ec7df39afc",
      "9ad0bb19973e460c9b2b3553f846baba",
      "2201b870b71d4af99782a27db97c5308",
      "4ec93432e5424c298dc04c650e5fd3b2",
      "b6f1a07491b4484791324866b94fcc3c",
      "f16c7dce5d874734be366433b7ec2647",
      "1e4dc8fb183b412f9bf420be9e4da6d6"
     ]
    },
    "id": "5uyHgnMN3R9X",
    "outputId": "d008d703-1e5b-4093-d770-01e5ffe7cf8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 text file(s)\n",
      "  - ubertext_data/ubertext.wikipedia.filter_rus_gcld+short.text_only.txt: 4393.4 MB\n",
      "\n",
      "[Step 1/3] Reading and chunking files...\n",
      "  Reading ubertext.wikipedia.filter_rus_gcld+short.text_only.txt... 2,637,228,384 chars -> 918,276 chunks (57.0s)\n",
      "  Total raw chunks: 918,276\n",
      "\n",
      "[Step 2/3] Filtering chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████| 918276/918276 [08:21<00:00, 1830.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Valid chunks after filtering: 899,246 (97.9%)\n",
      "\n",
      "  Saving chunks to chunks_cache.pkl...\n",
      "  Cache saved!\n",
      "\n",
      "[Step 3/3] Building embeddings and FAISS index...\n",
      "  This will process 899,246 chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df89ec99f4b4944abae4f8756d96303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0984744dc2884abfa7e7c020332cb8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a3fbbffec74c2db48b78a8f0c3c146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff62af56e7854cf982b294d08f8ce6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd63744934274dc3991788ff1b07a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eece2a69bff149338a1d066fb5673e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6be14054b74a93beffb7f93d02ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e98c5a927a345c187d7c3563cb9bd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4154d93c864f41349bef69a1891fded8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f4be0ab706419b876626f80bea5fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fd96b67de8466db62fb70f2b86367f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embeddings + index built in 1179.1s\n",
      "\n",
      "Index saved to faiss_index: 899,246 chunks\n"
     ]
    }
   ],
   "source": [
    "vectorstore = build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "QCPzh8lx4iqB",
    "outputId": "eef11bad-a372-4e31-f1ea-0fdf4186dd64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating submission: 100%|██████████| 751/751 [31:32<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"create_submission(model, tokenizer, vectorstore)\",\n  \"rows\": 751,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 216,\n        \"min\": 0,\n        \"max\": 750,\n        \"num_unique_values\": 751,\n        \"samples\": [\n          473,\n          357,\n          133\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0410\",\n          \"\\u0411\",\n          \"\\u0414\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b8ea93e1-ccc1-4931-aeb1-0a8240554bbc\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>correct_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>А</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Д</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>В</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>746</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>747</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>748</td>\n",
       "      <td>Б</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>Г</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8ea93e1-ccc1-4931-aeb1-0a8240554bbc')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b8ea93e1-ccc1-4931-aeb1-0a8240554bbc button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b8ea93e1-ccc1-4931-aeb1-0a8240554bbc');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      id correct_answers\n",
       "0      0               Г\n",
       "1      1               Г\n",
       "2      2               А\n",
       "3      3               Д\n",
       "4      4               В\n",
       "..   ...             ...\n",
       "746  746               Г\n",
       "747  747               Г\n",
       "748  748               Б\n",
       "749  749               Г\n",
       "750  750               Г\n",
       "\n",
       "[751 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission(model, tokenizer, vectorstore)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "H100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}